{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a id=\"open-existing-db\"></a>\n",
    "###  Import the correct libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "//import libraries\n",
    "import org.apache.spark.{SparkConf, SparkContext, SparkFiles}\n",
    "import org.apache.spark.sql.{SQLContext, SparkSession, Row}\n",
    "import org.apache.spark.SparkFiles\n",
    "\n",
    "import org.apache.spark.ml.feature.{StringIndexer, IndexToString, VectorIndexer, VectorAssembler}\n",
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.classification.{LogisticRegression, DecisionTreeClassifier}\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.{Pipeline, PipelineStage}\n",
    "import org.apache.spark.ml.ibm.transformers.RenameColumn\n",
    "\n",
    "import com.ibm.analytics.ngp.repository._\n",
    "import com.ibm.analytics.ngp.ingest.Sampling\n",
    "import com.ibm.analytics.ngp.util._\n",
    "import com.ibm.analytics.ngp.pipeline.evaluate.{Evaluator,MLProblemType}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"open-existing-db\"></a>\n",
    "###  Open the IBM Db2 Event store database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import com.ibm.event.oltp.EventContext\n",
    "val eContext = EventContext.getEventContext(\"KillrWeather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"validate-db\"></a>\n",
    "###  Validate that the table have been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val raw_weather_data = eContext.getTable(\"raw_weather_data\")\n",
    "val sky_condition_lookup = eContext.getTable(\"sky_condition_lookup\")\n",
    "val monthly_aggregate_precip = eContext.getTable(\"monthly_aggregate_precip\")\n",
    "val monthly_aggregate_windspeed = eContext.getTable(\"monthly_aggregate_windspeed\")\n",
    "val monthly_aggregate_pressure = eContext.getTable(\"monthly_aggregate_pressure\")\n",
    "val monthly_aggregate_temperature = eContext.getTable(\"monthly_aggregate_temperature\")\n",
    "val daily_aggregate_precip = eContext.getTable(\"daily_aggregate_precip\")\n",
    "val daily_aggregate_windspeed = eContext.getTable(\"daily_aggregate_windspeed\")\n",
    "val daily_aggregate_pressure = eContext.getTable(\"daily_aggregate_pressure\")\n",
    "val daily_aggregate_temperature = eContext.getTable(\"daily_aggregate_temperature\")\n",
    "val daily_predicted_temperature = eContext.getTable(\"daily_predicted_temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-sqlContext\"></a>\n",
    "### Create the IBM Db2 EventSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import java.io.File\n",
    "import com.ibm.event.oltp.EventContext\n",
    "import org.apache.log4j.{Level, LogManager, Logger}\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.ibm.event.EventSession\n",
    "\n",
    "val sqlContext = new EventSession(spark.sparkContext, \"KillrWeather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare-DataFrame\"></a>\n",
    "### Prepare a DataFrame for the query \n",
    "The following API provides a DataFrame that holds the query results on the IBM Db2 Event Store table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val dfDailyTemp = sqlContext.loadEventTable(\"daily_aggregate_temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- wsid: string (nullable = false)\n",
      " |-- year: integer (nullable = false)\n",
      " |-- month: integer (nullable = false)\n",
      " |-- day: integer (nullable = false)\n",
      " |-- ts: long (nullable = false)\n",
      " |-- high: double (nullable = false)\n",
      " |-- low: double (nullable = false)\n",
      " |-- mean: double (nullable = false)\n",
      " |-- variance: double (nullable = false)\n",
      " |-- stdev: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfDailyTemp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDailyTemp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+-----+---+-------------+----+---+------------------+------------------+------------------+\n",
      "|        wsid|year|month|day|           ts|high|low|              mean|          variance|             stdev|\n",
      "+------------+----+-----+---+-------------+----+---+------------------+------------------+------------------+\n",
      "|725030:14732|2017|    2|  1|1488355200333| 3.9|0.0|2.1541666666666663|1.0841493055555556| 1.041224906326945|\n",
      "|725030:14732|2017|    2|  2|1488441600334|12.2|0.0| 6.216666666666667|  6.12888888888889| 2.475659283683619|\n",
      "|725030:14732|2017|    2|  3|1488528000334|10.0|0.0|            4.4375| 8.139010416666666|2.8528950938768616|\n",
      "|725030:14732|2017|    2|  4|1488614400335| 7.8|0.0| 3.858333333333333| 4.009097222222221|2.0022730139074993|\n",
      "|725030:14732|2017|    2|  5|1488700800336|11.1|0.0| 6.929166666666666|10.974565972222223|3.3127882474167016|\n",
      "+------------+----+-----+---+-------------+----+---+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfDailyTemp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.lag\n",
    "import org.apache.spark.sql.functions.col \n",
    "\n",
    "val w = org.apache.spark.sql.expressions.Window.orderBy(\"year\", \"month\", \"day\")  \n",
    "\n",
    "val dfTrain = dfDailyTemp.withColumn(\"mean1\", lag(col(\"mean\"), 1, null).over(w)).\n",
    "    withColumn(\"mean2\", lag(col(\"mean\"), 2, null).over(w)).\n",
    "    withColumn(\"mean3\", lag(col(\"mean\"), 3, null).over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+\n",
      "|               mean|             mean1|             mean2|             mean3|\n",
      "+-------------------+------------------+------------------+------------------+\n",
      "|  5.345833333333333|              null|              null|              null|\n",
      "| 1.5708333333333329| 5.345833333333333|              null|              null|\n",
      "|             -6.875|1.5708333333333329| 5.345833333333333|              null|\n",
      "| -3.287500000000001|            -6.875|1.5708333333333329| 5.345833333333333|\n",
      "|              2.925|-3.287500000000001|            -6.875|1.5708333333333329|\n",
      "|  4.887499999999999|             2.925|-3.287500000000001|            -6.875|\n",
      "|  9.508333333333333| 4.887499999999999|             2.925|-3.287500000000001|\n",
      "| 13.583333333333332| 9.508333333333333| 4.887499999999999|             2.925|\n",
      "| 12.112499999999999|13.583333333333332| 9.508333333333333| 4.887499999999999|\n",
      "|  8.254166666666666|12.112499999999999|13.583333333333332| 9.508333333333333|\n",
      "|  8.504166666666666| 8.254166666666666|12.112499999999999|13.583333333333332|\n",
      "|  8.283333333333331| 8.504166666666666| 8.254166666666666|12.112499999999999|\n",
      "|  5.195833333333334| 8.283333333333331| 8.504166666666666| 8.254166666666666|\n",
      "| 3.4250000000000007| 5.195833333333334| 8.283333333333331| 8.504166666666666|\n",
      "| 2.6791666666666667|3.4250000000000007| 5.195833333333334| 8.283333333333331|\n",
      "| 1.5624999999999998|2.6791666666666667|3.4250000000000007| 5.195833333333334|\n",
      "| 1.4208333333333334|1.5624999999999998|2.6791666666666667|3.4250000000000007|\n",
      "|              5.125|1.4208333333333334|1.5624999999999998|2.6791666666666667|\n",
      "| 2.5500000000000003|             5.125|1.4208333333333334|1.5624999999999998|\n",
      "|-1.4958333333333333|2.5500000000000003|             5.125|1.4208333333333334|\n",
      "+-------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfTrain.select(\"mean\", \"mean1\", \"mean2\", \"mean3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.round\n",
    "\n",
    "val dfTrain2 = dfTrain.withColumn(\"mean\", round(col(\"mean\"), 1)).\n",
    "    withColumn(\"mean1\", round(col(\"mean1\"), 1)).\n",
    "    withColumn(\"mean2\", round(col(\"mean2\"), 1)).\n",
    "    withColumn(\"mean3\", round(col(\"mean3\"), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val dfTrain3 = dfTrain2.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+-----+\n",
      "|mean|mean1|mean2|mean3|\n",
      "+----+-----+-----+-----+\n",
      "|-3.3| -6.9|  1.6|  5.3|\n",
      "| 2.9| -3.3| -6.9|  1.6|\n",
      "| 4.9|  2.9| -3.3| -6.9|\n",
      "| 9.5|  4.9|  2.9| -3.3|\n",
      "|13.6|  9.5|  4.9|  2.9|\n",
      "|12.1| 13.6|  9.5|  4.9|\n",
      "| 8.3| 12.1| 13.6|  9.5|\n",
      "| 8.5|  8.3| 12.1| 13.6|\n",
      "| 8.3|  8.5|  8.3| 12.1|\n",
      "| 5.2|  8.3|  8.5|  8.3|\n",
      "| 3.4|  5.2|  8.3|  8.5|\n",
      "| 2.7|  3.4|  5.2|  8.3|\n",
      "| 1.6|  2.7|  3.4|  5.2|\n",
      "| 1.4|  1.6|  2.7|  3.4|\n",
      "| 5.1|  1.4|  1.6|  2.7|\n",
      "| 2.6|  5.1|  1.4|  1.6|\n",
      "|-1.5|  2.6|  5.1|  1.4|\n",
      "|-5.9| -1.5|  2.6|  5.1|\n",
      "|-0.6| -5.9| -1.5|  2.6|\n",
      "| 3.1| -0.6| -5.9| -1.5|\n",
      "+----+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfTrain3.select(\"mean\", \"mean1\", \"mean2\", \"mean3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val splits = dfTrain3.randomSplit(Array(0.8, 0.20), seed = 24L)\n",
    "val training_data = splits(0)\n",
    "val test_data = splits(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log4j: reset attribute= \"false\".\n",
      "log4j: Threshold =\"null\".\n",
      "log4j: Retreiving an instance of org.apache.log4j.Logger.\n",
      "log4j: Setting [org.apache.zookeeper] additivity to [true].\n",
      "log4j: Level value for org.apache.zookeeper is  [off].\n",
      "log4j: org.apache.zookeeper level set to OFF\n",
      "log4j: Retreiving an instance of org.apache.log4j.Logger.\n",
      "log4j: Setting [org.apache.spark] additivity to [true].\n",
      "log4j: Level value for org.apache.spark is  [off].\n",
      "log4j: org.apache.spark level set to OFF\n",
      "log4j: Retreiving an instance of org.apache.log4j.Logger.\n",
      "log4j: Setting [com.ibm.event] additivity to [true].\n",
      "log4j: Level value for com.ibm.event is  [warn].\n",
      "log4j: com.ibm.event level set to WARN\n",
      "log4j: Retreiving an instance of org.apache.log4j.Logger.\n",
      "log4j: Setting [com.ibm.event.rest] additivity to [true].\n",
      "log4j: Level value for com.ibm.event.rest is  [debug].\n",
      "log4j: com.ibm.event.rest level set to DEBUG\n",
      "log4j: Level value for root is  [off].\n",
      "log4j: root level set to OFF\n",
      "log4j: Class name: [org.apache.log4j.ConsoleAppender]\n",
      "log4j: Setting property [target] to [System.out].\n",
      "log4j: Parsing layout of class: \"org.apache.log4j.PatternLayout\"\n",
      "log4j: Setting property [conversionPattern] to [%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n].\n",
      "log4j: Adding appender named [info-out] to category [root].\n",
      "log4j: Class name: [org.apache.log4j.ConsoleAppender]\n",
      "log4j: Setting property [target] to [System.err].\n",
      "log4j: Parsing layout of class: \"org.apache.log4j.PatternLayout\"\n",
      "log4j: Setting property [conversionPattern] to [%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n].\n",
      "log4j: Setting property [levelMin] to [WARN].\n",
      "log4j: Setting property [levelMax] to [FATAL].\n",
      "log4j: Setting property [acceptOnMatch] to [true].\n",
      "log4j: Adding filter of type [class org.apache.log4j.varia.LevelRangeFilter] to appender named [error-out].\n",
      "log4j: Adding filter of type [class org.apache.log4j.varia.DenyAllFilter] to appender named [error-out].\n",
      "log4j: Adding appender named [error-out] to category [root].\n"
     ]
    }
   ],
   "source": [
    "import com.ibm.spss.ml.classificationandregression.LinearRegression\n",
    "\n",
    "val linearRegression = LinearRegression().\n",
    "    setInputFieldList(Array(\"mean1\", \"mean2\", \"mean2\")).\n",
    "    setTargetField(\"mean\")\n",
    "\n",
    "val linearRegressionModel = linearRegression.fit(training_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|mean|          prediction|\n",
      "+----+--------------------+\n",
      "|-3.3|  -5.653836587694465|\n",
      "| 9.5|   5.687148623653268|\n",
      "| 1.4|   2.487573648313256|\n",
      "| 5.1|  2.4724313872074934|\n",
      "| 3.1|  2.1178894125917616|\n",
      "| 1.2|   6.764123897435455|\n",
      "|11.7|    7.49544742735073|\n",
      "| 4.0|    5.28478920377357|\n",
      "|-0.8|-0.35380177888684045|\n",
      "| 0.3|   2.033875205803433|\n",
      "| 2.1|   6.201294803722097|\n",
      "| 6.2|   2.781569136626652|\n",
      "| 4.0|   5.117098816560812|\n",
      "| 8.7|  11.792955239895084|\n",
      "| 7.6|   6.740866261676819|\n",
      "|12.4|  13.747574092820033|\n",
      "|11.9|    9.99893435664755|\n",
      "|13.0|  11.726393614336985|\n",
      "|15.1|  15.962792357838921|\n",
      "|10.5|  10.338547696441415|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val predictions = linearRegressionModel.transform(test_data)\n",
    "predictions.select(\"mean\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model in PMML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" ?><PMML version=\"4.3\" xmlns=\"http://www.dmg.org/PMML-4_3\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.dmg.org/PMML-4_3 http://www.dmg.org/v4-3/pmml-4-3.xsd\"><Header copyright=\"(c) Copyright IBM Corp. 2011, 2015\" description=\"linear engine\"><Application name=\"Analytic Framework\" version=\"3.0\"></Application><Timestamp>Sat Mar 3 20:35:13 2018</Timestamp></Header><DataDictionary numberOfFields=\"13\"><DataField name=\"wsid\" displayName=\"wsid\" optype=\"categorical\" dataType=\"string\"><Value value=\"725030:14732\" property=\"valid\"></Value></DataField><DataField name=\"year\" displayName=\"year\" optype=\"continuous\" dataType=\"integer\"></DataField><DataField name=\"month\" displayName=\"month\" optype=\"continuous\" dataType=\"integer\"></DataField><DataField name=\"day\" displayName=\"day\" optype=\"continuous\" dataType=\"integer\"></DataField><DataField name=\"ts\" displayName=\"ts\" optype=\"continuous\" dataType=\"integer\"></DataField><DataField name=\"high\" displayName=\"high\" optype=\"continuous\" dataType=\"double\"></DataField><DataField name=\"low\" displayName=\"low\" optype=\"continuous\" dataType=\"double\"></DataField><DataField name=\"mean\" displayName=\"mean\" optype=\"continuous\" dataType=\"double\"></DataField><DataField name=\"variance\" displayName=\"variance\" optype=\"continuous\" dataType=\"double\"></DataField><DataField name=\"stdev\" displayName=\"stdev\" optype=\"continuous\" dataType=\"double\"></DataField><DataField name=\"mean1\" displayName=\"mean1\" optype=\"continuous\" dataType=\"double\"></DataField><DataField name=\"mean2\" displayName=\"mean2\" optype=\"continuous\" dataType=\"double\"></DataField><DataField name=\"mean3\" displayName=\"mean3\" optype=\"continuous\" dataType=\"double\"></DataField></DataDictionary><GeneralRegressionModel modelType=\"generalLinear\" targetVariableName=\"mean\" algorithmName=\"LE\" functionName=\"regression\"><Extension extender=\"spss.com\" name=\"modelID\" value=\"0\"></Extension><MiningSchema><MiningField name=\"mean1\"></MiningField><MiningField name=\"mean2\"></MiningField><MiningField name=\"mean\" usageType=\"predicted\"></MiningField></MiningSchema><ModelStats><UnivariateStats field=\"mean\"><Anova><AnovaRow degreesOfFreedom=\"3.0\" fValue=\"739.6849033341923\" meanOfSquares=\"5529.788236511733\" pValue=\"0.0\" sumOfSquares=\"16589.3647095352\" type=\"Model\"></AnovaRow><AnovaRow degreesOfFreedom=\"232.0\" meanOfSquares=\"7.475870078712902\" sumOfSquares=\"1734.4018582613933\" type=\"Error\"></AnovaRow><AnovaRow degreesOfFreedom=\"235.0\" sumOfSquares=\"18323.766567796592\" type=\"Total\"></AnovaRow></Anova></UnivariateStats><UnivariateStats field=\"mean\"><Counts totalFreq=\"236.0\"></Counts><NumericInfo maximum=\"30.3\" mean=\"14.503813559322042\" minimum=\"-7.0\" standardDeviation=\"8.830259042439312\"></NumericInfo></UnivariateStats><UnivariateStats field=\"mean1\"><Counts totalFreq=\"236.0\"></Counts><NumericInfo maximum=\"31.6\" mean=\"14.497033898305089\" minimum=\"-7.0\" standardDeviation=\"8.868833290278992\"></NumericInfo></UnivariateStats><UnivariateStats field=\"mean2\"><Counts totalFreq=\"236.0\"></Counts><NumericInfo maximum=\"31.6\" mean=\"14.580084745762713\" minimum=\"-7.0\" standardDeviation=\"8.871387523298274\"></NumericInfo></UnivariateStats></ModelStats><Targets><Target field=\"mean\" optype=\"continuous\"></Target></Targets><ParameterList><Parameter label=\"Intercept\" name=\"P0000001\"></Parameter><Parameter label=\"mean1\" name=\"P0000002\"></Parameter><Parameter label=\"mean2\" name=\"P0000003\"></Parameter><Parameter label=\"mean2 * mean2\" name=\"P0000004\"></Parameter></ParameterList><CovariateList><Predictor name=\"mean1\"></Predictor><Predictor name=\"mean2\"></Predictor></CovariateList><PPMatrix><PPCell parameterName=\"P0000002\" predictorName=\"mean1\" value=\"1\"></PPCell><PPCell parameterName=\"P0000003\" predictorName=\"mean2\" value=\"1\"></PPCell><PPCell parameterName=\"P0000004\" predictorName=\"mean2\" value=\"2\"></PPCell></PPMatrix><ParamMatrix><PCell beta=\"1.3894286045739992\" df=\"1\" parameterName=\"P0000001\"></PCell><PCell beta=\"0.9790684307110793\" df=\"1\" parameterName=\"P0000002\"></PCell><PCell beta=\"-0.1890297008036651\" df=\"1\" parameterName=\"P0000003\"></PCell><PCell beta=\"0.005763476923377929\" df=\"1\" parameterName=\"P0000004\"></PCell></ParamMatrix></GeneralRegressionModel></PMML>\n"
     ]
    }
   ],
   "source": [
    "val pmml = linearRegressionModel.toPMML()\n",
    "System.out.println(pmml.toString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Model to Lightbend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val service_path = \"http://\"\n",
    "val online_path = service_path + \"/v2/deployments\"\n",
    "\n",
    "val response_online = Http(online_path).postData(pmml.toString).header(\"Content-Type\", \"application/xml\").option(HttpOptions.connTimeout(10000)).option(HttpOptions.readTimeout(50000)).asString\n",
    "\n",
    "print (response_online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2017. Released as licensed Sample Materials."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
